version: '3.8'

services:

  ollama:
    build:
      context: .
      dockerfile: ./bin/olamma/Dockerfile
    volumes:
      - ~/.aws:/root/.aws
    env_file:
      - .env
    command: ["/workspace/run_ollama.sh"]
    container_name: ollama
    networks:
      - llm-network
    tty: true
    restart: unless-stopped


  agent-container:
    build:
      context: .
      dockerfile: ./bin/agent/Dockerfile
    env_file:
      - .env
    depends_on:
      - ollama
    container_name: global-path-finding-agent-container
    volumes:
      - ~/.aws:/root/.aws
      - ./wait-for-it.sh:/wait-for-it.sh
      - ./config.yaml:/workspace/config.yaml
    network_mode: "host"
    command: ["uvicorn", "run:app", "--host", "0.0.0.0", "--port", "8000"]

networks:
  llm-network:
    driver: bridge